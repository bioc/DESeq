%\VignetteIndexEntry{Analysing RNA-Seq data with the "DESeq" package}
%\VignettePackage{DESeq}

% To compile this document
% library('weaver'); rm(list=ls()); Sweave('DESeq.Rnw', driver=weaver()); system('pdflatex DESeq')

\documentclass{article}

\usepackage{Sweave}
\usepackage[a4paper]{geometry}
\usepackage{hyperref,graphicx}
\usepackage{natbib}
\usepackage{color}

\SweaveOpts{keep.source=TRUE,eps=FALSE,include=FALSE,width=4,height=4.5} 
\newcommand{\Robject}[1]{\texttt{#1}}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rfunction}[1]{{\small\texttt{#1}}}
\newcommand{\fixme}[1]{{\textbf{Fixme:} \textit{\textcolor{blue}{#1}}}}

\author{Simon Anders\\[1em]European Molecular Biology Laboratory (EMBL),\\ Heidelberg, Germany\\[1em]
\texttt{sanders@fs.tum.de}}

\title{\textsf{\textbf{Analysing RNA-Seq data with the \Rpackage{DESeq} package}}}

\begin{document}

\maketitle

\begin{center}
  \fbox{\parbox{.7\textwidth}{
\textbf{Notice:} This is the vignette of the development version of
DESeq. The \Rpackage{DESeq} package is currently undergoing a major overhaul, and 
users are advised to work with the release version, until this note is removed.}}
\end{center}


\tableofcontents

\begin{abstract} 
A basic task in the analysis of count data from RNA-Seq is the detection of differentially expressed genes.  
The count data are presented as a table which reports, for each sample, the number of reads that have been 
assigned to a gene. Analogous analyses also arise for other assay types, such as comparative ChIP-Seq.
The package \Rpackage{DESeq} provides a method to test for differential 
expression by use of a shrinkage estimtor for the variance\footnote{Other Bioconductor packages 
  for this use case are \Rpackage{edgeR} and \Rpackage{baySeq}.}. 
This vignette explains the use of the package. For an exposition of 
the statistical method employed, please see our paper~\cite{Anders:2010:GB}.
\end{abstract}

%--------------------------------------------------
\section{Input data and preparations} \label{sec:prep}
%--------------------------------------------------

The \Rpackage{DESeq} package expects count data, as obtained, e.g.,
from an RNA-Seq or other high-throughput sequencing (HTS) experiment,
in the form of a matrix of integer values. Each column corresponds to
a sample, e.g., one library preparation or one lane.
The rows correspond to the entities for which you want to compare coverage, 
e.\,g.\ to a gene, to a binding region in a ChIP-Seq dataset, 
a window in CNV-Seq or the like. So, for a typical RNA-Seq experiment, each
element in the table tells how many reads have been mapped in a given sample
to a given gene. 

To obtain such a count table for your own data, you will need
to create it from the sequence alignments by use of tools outside of the
\Rpackage{DESeq} package. For instance, in the course materials
available on the Bioconductor web page, there are examples for how to
do this with the \Rpackage{ShortRead} and \Rpackage{IRanges}
packages. \textsl{TODO: Add a reference to these.}

Another, easy way to produce such a table from the output
  of the aligner is to use the \texttt{htseq-count} script distributed
  with the \emph{HTSeq} package. Even though \emph{HTSeq} is a Python
  package, you do not need to know any Python to use
  \texttt{htseq-count}. See
  \url{http://www-huber.embl.de/users/anders/HTSeq/doc/count.html}.

The count values must be raw counts of
sequencing reads. This is important for DESeq's statistical model to hold,
as only raw reads allow to assess the measurement precision correctly. (Hence,
do not supply rounded values of normalized counts, or counts of covered base pairs.)

Furthermore, it is important that each column stems from an independent biological
replicate.  For purely technical replicates (e.\,g. when the same
library preparation was distributed over multiple lanes of the
sequencer in order to increase coverage), please sum up their counts
to get a single column, corresponding to a unique biological
replicate.  This is needed in order to allow \Rpackage{DESEq} to
estimate variability in the experiment correctly.

As an example dataset, we use the gene level read counts from the
\Rpackage{pasilla} package. This dataset is from an experiment on
\emph{Drosophila melanogaster} cell cultures. The experiment
investigated the effect of RNAi knock down of the splicing factor
\emph{pasilla}~\cite{Brooks2010}. The data are presented in the object
called \Robject{pasillaGenes}. The object is of class
\Rclass{CountDataSet}, which is the data container used by
\Rpackage{DESeq}. We load the needed packages and the data as
follows.

<<pasilla2,results=hide>>=
library( "DESeq" )
library( "pasilla" )
data( "pasillaGenes" )
@

\Robject{pasillaGenes} contains the counts and also metadata about the samples:

<<look_into_pasillaGenes>>=
head( counts(pasillaGenes) )
pData( pasillaGenes )
@

As you can see, the samples differ by experimental condition (untreated or treated, i.\,e., with
pasilla knocked down) and by library type. To keep things simple, we will only 
look at the paired-end data for now. In Section \ref{sec:GLM}, we will see how to deal 
with more than one factor.

For your own analysis, you will start form a count table, so we ``unpack'' the 
\Rclass{countDataSet} object and build a new one ``from scratch'' to demonstrate how this is done.

<<pairedSamples>>=
pairedSamples <- pData(pasillaGenes)$type == "paired-end"
countsTable <- counts(pasillaGenes)[ , pairedSamples ]
conds <- pData(pasillaGenes)$condition[ pairedSamples ]
@

Now, we have a count table, as described above, of integer count data. For your own data,
use R's \Rfunction{read.table} or \Rfunction{read.csv} function to read your count data
from a text file. For details how this specific count table was created from the
raw data, see the vignette of the \Rpackage{pasilla} package.

We also need a description of the samples, which is here simply a factor:

<<conds>>=
conds
@

For your own data, create such a factor simply with 
<<conds,eval=FALSE>>=
#not run
conds <- factor( c( "treated", "treated", "untreated", "untreated" ) )
@

We can now instantiate a \Rclass{CountDataSet}, which is the central
data structure in the \Rpackage{DESeq} package:
%
<<instantiate>>=
cds <- newCountDataSet( countsTable, conds )
@

The \Rclass{CountDataSet} class is derived from \Rpackage{Biobase}'s
\Rclass{eSet} class and so shares all features of this standard
Bioconductor class. Furthermore, accessors are provided for its data
slots\footnote{In fact, the objects \Robject{pasillaGenes} and \Robject{cds}
  from the \Rpackage{pasilla} are also of class \Rclass{CountDataSet};
  here we re-created \Robject{cds} from elementary datatypes, a matrix and a factor,
  for pedagogic effect.}.  For example, the counts can be accessed with the
\Rfunction{counts} function.
%
<<headcounts1>>=
head( counts(cds) )
@
%

As first processing step, we need to estimate the effective library
size. This information is called the ``size factors'' vector, as the
package only needs to know the relative library sizes. So, if the counts
of non-differentially expressed genes in one sample are, on average, twice as high 
as in another, the size factor for the first sample should be
twice as large as the one for the other sample. The function
\Rfunction{estimateSizeFactors} estimates the size factors from the
count data. (See the man page of
\Rfunction{estimateSizeFactorsForMatrix} for technical details on the
calculation.)
%
<<estimateSizeFactors,cache=TRUE>>=
cds <- estimateSizeFactors( cds )
sizeFactors( cds )
@

If we divide each column of the count table by the size factor for this column, the
count values are brought to a common scale, making them comparable. When called
with \texttt{normalized=TRUE}, the \texttt{counts} accessor function performs this
calculation. This is useful, e.g., for visualization.
%
<<headcounts2>>=
head( counts( cds, normalized=TRUE ) )
@

%------------------------------------------------------------
\section{Variance estimation}
%------------------------------------------------------------

The inference in \Rpackage{DESeq} relies on an estimation of the typical
relationship between the data's variance and their mean, or, equivalently,
between the data's dispersion and their mean~\cite{Anders:2010:GB}.
This estimation is done by calculating, for each gene, 
the sample mean $\mu$ and sample variance $v$ within replicates, and the
dispersion
\begin{equation}
\alpha = \frac{v-\mu}{\mu^2}.
\end{equation}
When the number of replicates is not large, the precision of these
values is low, i.\,e.\ they will tend to fluctuate strongly, and one of the features
of the \Rpackage{DESeq} method is to increase their precision by "sharing information"
across genes through fitting a smooth curve to the graph of $\alpha$ versus $\mu$ for all genes.

\fixme{What follows is a lot of philosophy that I think is not at the right place here.
  It might scare away people who just want to use the method. 
  It could be moved to a later section (like an appendix), but then should gain some 
  substance by showing diagnostic plots that demonstrate the variance components,
  e.g. by focusing at the high and low ends of the dynamic range, where one or the other dominates.}

\verb+\begin{philosophy}+\\
In RNA-Seq, the variance results from two components, technical and the biological variability.
Biological variability results, for instance, from variations in the concentration of cDNA fragments from a given
gene in different replicate samples obtained under the same experimental condition. 
Technical variability is caused by the fact that the data arise from discrete
counting. From theoretical considerations,
it can be seen\footnote{Please see our paper and reference therein.} that 
the technical noise cannot be lower than what the Poisson distribution predicts,
namely that the variance is equal to the mean. As Nagalakshmi et al.\ and Marioni et al.\ 
showed, the technical noise is indeed not much higher than this theoretical minimum (at least if
everything went well with sample preparation) and hence, we assume the variance contribution
from technical noise to be equal to the mean and refer to it as the Poisson or shot noise. 

% The next paragraph seems pointless - are these definitions needed for anything that follows?
%The difference between 
%observed variance and Poisson variance, i.e., the difference between variance and mean, is hence
%the biological variation. (Note that this ``biological'' variance also includes noise
%from technical steps prior to sequencing; however, the part due to biological differences
%in the samples and their responses to treatment usually dominates, hence we use the
%term ``biological variance'' for the whole difference of observed variance and mean.)

It is helpful to present the biological variance as a coefficient of variation (CV),
i.e., as the ratio of standard deviation to mean. For an observed variance $v$ and
mean $\mu$, the biological variation is $v-\mu$ and the biological CV is hence 
$\sqrt{v-\mu}/\mu$. If it takes a value of, say, 0.15, this means roughly that the  
concentration of fragments from the gene typically changes by 15\% from a sample to
its biological replicate sample. For mathematical reasons, \textit{DESeq}, instead
uses the square of the biological variation, i.e., the quantity $(v-\mu)/\mu^2$, 
which is called the dispersion or the raw squared coefficient of 
variation (raw SCV)).\\
\verb+\end{philosophy}+

To estimate the dispersion, use this command.
<<estimateDispersions,cache=TRUE>>=
cds <- estimateDispersions( cds )
@

We could now proceed straight to the testing for differetial
expression in Section~\ref{sec:DE}.  However, it is prudent to check
the dispersion estimates and to make sure that the data quality is as
expected.

The function \Rfunction{estimateDispersions} performs two steps. First, it estimates,
for each gene and each (replicated) condition, a dispersion value, then, it fits,
for each condition, a curve through the estimates. To allow the user to inspect the
intermediate steps, a ``fit info'' object is stored for each condition:

<<ls>>=
ls( cds@fitInfo )
@

Each of the objects in the environment \Robject{cds@fitInfo} contains
the empirical dispersion values for each gene, the curve fitted through the dispersions,
and the fitted values that will be used in the test.

<<str>>=
str( cds@fitInfo[["untreated"]] )
@

\begin{figure}
\centering
\includegraphics[width=.66\textwidth]{DESeq-figFitTwithQuantiles}
\caption{Estimated (black) and fitted (red) dispersion values for condition ``untreated'',
plotted against mean expression strength.
The blue line indicates the 99-percentile of the theoretical sampling
distribution for dispersion estimates.}
\label{figFitT}
\end{figure}

To visualize these, we plot the per-gene estimates against the normalized mean 
expressions per gene, and the overlay the fitted values in red:

<<figFitT,fig=TRUE>>=
cond <- "untreated"
means <- rowMeans( counts( cds, normalized=TRUE ) )
plot(   means, cds@fitInfo[[cond]]$perGeneDispEsts, log="xy", pch="." )
points( means, cds@fitInfo[[cond]]$fittedDispEsts, pch=".", col="red" )
@

The plot (Fig.~\ref{figFitTWithQuantiles}) is doubly logarithmic; this may be helpful or
misleading, and it is worth experimenting with other plotting styles.
\fixme{The boundary effects of the smoothing line look awful - I understand this may not
       be a big problem in practice, but then we should also show a plot that
       deemphasizes them. Perhaps show the fit only within the \[0.025,0.975\] 
       range of the x-axis?}

In any case, we could be worried by the genes at the upper end of the plot.
Can we really assume hese to have the same variance as the other genes
with similar expression? As we estimated the dispersion from
only three samples we should expect the estimates to scatter with quite some
sampling variance around their true values. To quantify this, we assume that
dispersion estimates scatter around their true values according to a scaled
$chi^2$ distribution with the appriate number of degrees of freedom (here: 1=2-1, as we
have 2 samples and estimate one nuisance parameter, the mean). We redo the
plot with lines indicating the 5- and 95-percentil of this distribution:

<<figFitTwithQuantiles,fig=TRUE>>=
plot( means, cds@fitInfo[[cond]]$perGeneDispEsts, log="xy", pch="." )
xg <- 10^seq( min(log10(means[means>0])), max(log10(means)), length.out=1000 )
df <- sum( conditions(cds) == cond ) - 1
lines( xg, cds@fitInfo[[cond]]$dispFunc( xg ), col="red" )
lines( xg, cds@fitInfo[[cond]]$dispFunc( xg ) * qchisq( .99, df )/df, col="blue")
@ %$

There are a substantial number of genes above the 95\% line, definitely more than
5\% of the genes. Hence, it may be imprudent to use the fitted values (red dots
in Fig.\ \ref{figFitT}) for these genes. Just using the estimated values and
disregarding the fit would be improper as well as we the wide sampling distribution shows
that we can underestimate a dispersion substantially, leading to false positives.
A simple solution is to use whichever is the more conservative of the two numbers,
i.e., to use the \textit{maximum} of the fitted values and the per-gene estimate.

Hence, we redo the dispersion estimation, this time as follows:

<<estimateDispersions2,cache=TRUE>>=
cds <- estimateDispersions( cds, sharingMode="maximum" )
@

The argument \texttt{sharingMode} controls how information is shared across genes.
It can take the values \texttt{fit-only} (the default; use only the fitted values),
\texttt{maximum} (the compromise just described) and \texttt{gene-est-only} (ignore
the fit, directly use the per-gene estimates; usually not appriate, see above).

In any case, the dispersion values which finally should be used by the test are stored in
the feature data slot of \texttt{cds}:

<<head>>=
head( fData(cds) )
@

Now, \texttt{disp\_T} contains the maximum of the two value vectors we looked at before,
namely 

<<str>>=
str( cds@fitInfo[["untreated"]] )
@

Advanced users who may want to fiddle with the dispersion estimation can change the values
in \texttt{fData(cds)} priot to calling the testing function.

It is instructive to observe at which count level the biological 
noise starts to dominate the shot noise. At low counts, where shot noise dominates, higher
sequencing depth (larger library size) will improve the signal-to-noise ratio while
for high counts, where the biological noise dominates, only additional biological 
replicates will help. 


\section{Inference: Calling differential expression} \label{sec:DE}

Having estimated and verified the variance--mean dependence, it is now straight-forward to look for
differentially expressed genes. To contrast two conditions, e.g., to see whether there is differential
expression between conditions ``N'' and ``T'', we simply call the function \Rfunction{nbinomTest}.
It performs the tests as described in the paper and returns a data frame with the $p$ value and other
useful data.
%
<<nbt,cache=TRUE>>=
res <- nbinomTest( cds, "untreated", "treated" )
head(res)
@
%
For each gene, we get its mean expression level (at the base scale) as a joint estimate from both conditions, and
estimated separately for each  condition, the fold change from
the first to the second condition, the logarithm (to basis 2) of the fold change, and the
$p$ value for the statistical significance of this change. The \texttt{padj} column contains the 
$p$ values, adjusted for multiple testing with the Benjamini-Hochberg procedure (see the standard R function
\Rfunction{p.adjust}), which controls false discovery 
rate (FDR). The last two columns show the ratio of the single gene estimates for the base
variance to the fitted value. This may help to notice false hits due to ``variance outliers''. Any hit
that has a very large value in one these two columns should be checked carefully.

\begin{figure}
\centering
\includegraphics[width=.6\textwidth]{DESeq-figDE}
\caption{MvA plot for the contrast ``T'' vs.\ ``N''.}
\label{figDE}
\end{figure}

Let us first plot the $\log_2$ fold changes against the base means, colouring in red those genes
that are significant at 10\% FDR.
<<figDE,fig=TRUE>>=
plotDE <- function( res )
   plot( 
      res$baseMean, 
      res$log2FoldChange, 
      log="x", pch=20, cex=.3, 
      col = ifelse( res$padj < .1, "red", "black" ) )

plotDE( res )
@
See Fig.~\ref{figDE} for the plot. As we will use this plot more often, we have
stored its code in a function.

We can filter for the significant genes, 
<<ressig1>>=
resSig <- res[ res$padj < .1, ]
@
and list, e.g., the most significantly differentially expressed genes:
<<ressig2>>=
head( resSig[ order(resSig$pval), ] )
@

We may also want to look at the most strongly down-regulated of the significant
genes,
<<ressig3>>=
head( resSig[ order( resSig$foldChange, -resSig$baseMean ), ] )
@
or at the most strongly up-regulated ones:
<<ressig4>>=
head( resSig[ order( -resSig$foldChange, -resSig$baseMean ), ] )
@

To save the output to a file, use the R functions \Rfunction{write.table} and
\Rfunction{write.csv}. (The latter is useful if you want to load the table in a
spreadsheet program such as Excel.)

<<writetable,eval=FALSE>>=
#not run
write.table( res, file="results.txt" )
@

\subsection{Working partially without replicates}

If you have replicates for one condition but not for the other, you can still proceed as
before. As already stated above, the testing function will simply take the maximum of all 
estimated variance function for conditions without replicates. Whether this is acceptable,
needs to be checked, of course, but often, it may seem reasonable to assume that the variance
in your unreplicated conditions is not that differen from what you see in the replicated
ones.

To demonstrate, we subset our data object to only three samples:

<<subset>>=
cdsTTU <- cds[ , 1:3] 
pData( cdsTTU )
@

\begin{figure}
\centering
\includegraphics[width=.6\textwidth]{DESeq-figDE_Tb}
\caption{MvA plot for the contrast ``treated'' vs.\ ``untreated'', using two treated and
only one untreated sample.}
\label{figDE_Tb}
\end{figure}

Now, we do the analysis as before, and get a similar result:

<<est123,cache=TRUE>>=
cdsTTU <- estimateSizeFactors( cdsTTU )
cdsTTU <- estimateDispersions( cdsTTU )
resTTU <- nbinomTest( cdsTTU, "untreated", "treated" )
@

We produce the same plot as before, again with
<<figDE_Tb,fig=TRUE>>=
plotDE( resTTU )
@ %$
The result (Fig.~\ref{figDE_Tb}) shows the same symmetry in up- and down-regulation
as in Fig.~\ref{figDE} but a striking asymmetry in the boundary line for significance. This
has an easy explanation: low counts suffer from proportionally stronger shot noise than high counts, and this
is more pronounced in the ``Tb'' data than in the ``N'' data due to the lack of replicates. Hence
a stronger signal is required to call a down-regulation significant than for an up-regulation.


\subsection{Working without any replicates}

Proper replicates are essential to interpret a biological experiment. After all, if one compares two
conditions and finds a difference, how else would one know that this difference is due to the different conditions
and would not have arisen between replicates, as well, just due to noise? Hence, any attempt to work without any
replicates will lead to conclusions of very limited reliability.

Nevertheless, such experiments are often undertaken, especially in HTS, and the \Rpackage{DESeq} package
can deal with them, even though the soundness of the results may depend very much on the circumstances.

Our primary assumption is still that the mean is a good predictor for the variance. Hence, if a number of genes 
with similar expression level are compared between replicates, we expect that their variation is of
comparable magnitude. Once we accept this assumption, we may argue as follows: Given two samples from 
different conditions and a number of genes with comparable expression levels, of which we expect only a minority
to be influenced by the condition, we may take the variance estimated from comparing their count rates \emph{across}
conditions as ersatz for a proper estimate of the variance across replicates. After all,
we assume most genes to behave the same within replicates as across conditions, and hence, the estimated variance 
should not change too much due to the influence of the hopefully few differentially expressed genes. Furthermore,
the differentially expressed genes will only cause the variance estimate to be too high, so that the test will err to the
side of being too conservative, i.e., we only lose power.

We shall now see how well this works for our example data, even though it has rather many differentially expressed genes.

We reduce our count data set to just two columns, one ``untreated'' and one ``treated'' sample:
<<subset2>>=
cds2 <- cds[ ,c(  "untreated3fb", "treated3fb"   ) ]
@

Now, without any replicates at all, the \Rfunction{estimateDispersions} function will refuse to proceed unless we 
instruct it to ignore the condition labels and estimate the variance by treating all
samples as if they were replicates of the same condition:
<<cds2,cache=TRUE>>=
cds2 <- estimateDispersions( cds2, method="blind" )
@

Now, we can attempt to find differential expression:
<<res2,cache=TRUE>>=
res2 <- nbinomTest( cds2, "untreated", "treated" )
@

\begin{figure}
\centering
\includegraphics[width=.6\textwidth]{DESeq-figDE2}
\caption{MvA plot, from a test using no replicates.}
\label{figDE2}
\end{figure}

Unsurprisingly, we find much fewer hits, as can be seen from the plot (Fig.\ \ref{figDE2})
<<figDE2,fig=TRUE>>=
plotDE( res2 )
@
and from this table, tallying the number of significant hits in our previous and our new, restricted analysis:
<<addmarg>>=
addmargins( table( res_sig = res$padj < .1, res2_sig = res2$padj < .1 ) )
@
As can be seen, we have still found about 1/5 of the hits, and only a reassuringly small number of 
new (and potentially false) hits. \textsl{TODO: pdate discussion!}

One may finally ask whether the reduction of discoveries to a quarter is due to the higher variance
estimate, or due to the lower confidence in the base mean estimates, which is due to the reduced
sample size. To see this, we run the original analysis again, but now using the new, worse variance function. 

To do so, we just copy the dispersion values from the feature data of \texttt{cds2}
to a copy of \texttt{cds}:

<<cdsB,cache=TRUE>>=
cdsB <- cds
fData(cdsB) <- fData(cds2)
resB <- nbinomTest( cdsB, "untreated", "treated" )

addmargins( table( 
   res_sig = res$padj < .1, 
   resB_sig = resB$padj < .1 ) )
@

%In conclusion, the worse variance estimates costs less in power than the reduction
%in sample size. For another data set, this may well be quite different.

\textsl{TODO: This is an incorrect comparison. We are comparing here
a two tests with different sharingMode setting.}

%-------------------------------------------------------------------------------------------------
\section{Multi-factor designs} \label{sec:GLM}
%-------------------------------------------------------------------------------------------------

Let us return to the full pasilla data set, which we got as \Robject{pasillaGenes}
from the \Rpackage{pasilla} package. Due to the usage of both single-end
and paired-end libraries, it has a design with two factors,  \emph{condition}
(or treatment) and library \emph{type}:

<<design>>=
design <- pData(pasillaGenes)[ , c("condition","type") ]
design
@

When creating a count data xset with multiple factors, just pass a data frame
instead of the condition factor:

<<fct>>=
fullCountsTable <- counts( pasillaGenes )

cdsFull <- newCountDataSet( fullCountsTable, design )
@

\Robject{cdsFull} is now essentially the same object as \Robject{pasillaGenes},
we have only recreated it for demonstration.

As before, we estimate the size factors and then the dispersions. For the latter,
we specify the method ``pooled''. Then, only one dispersion is for each gene, 
an average over all cells (weighted by the number of samples for each cells), where
the term \emph{cell} denotes any of the four combinations of factor levels of
the design.

<<estsfdisp,cache=TRUE>>=
cdsFull <- estimateSizeFactors( cdsFull )
cdsFull <- estimateDispersions( cdsFull, method="pooled", sharingMode="maximum" )
@

\begin{figure}
\centering
\includegraphics[width=.7\textwidth]{DESeq-figFitTwithQuantilesFull}
\caption{Estimated (black) pooled dispersion values for all seven samples, with
regression curve and 5- and 95-percentiles of theoretical sampling
distribution for dispersion estimates.}
\label{figFitTwithQuantilesFull}
\end{figure}


As we now have more samples to estimate variance, we get better estimates. Comparing
with our previous results using only four samples, we can see the effect of
the additional degrees of freedom (Fig.~\ref{figFitTwithQuantilesFull}).

<<figFitTwithQuantilesFull,fig=TRUE>>=
cond <- "pooled"
plot( means, cdsFull@fitInfo[[cond]]$perGeneDispEsts, log="xy", pch=".", ylim=c(1e-4,1e2) )
xg <- 10^seq( min(log10(means[means>0])), max(log10(means)), length.out=1000 )
lines( xg, cdsFull@fitInfo[[cond]]$dispFunc( xg ), col="blue" )
df <- 7 - 2  # seven samples and 2 design factors
lines( xg, cdsFull@fitInfo[[cond]]$dispFunc( xg ), col="blue" )
lines( xg, cdsFull@fitInfo[[cond]]$dispFunc( xg ) * qchisq( .05, df )/df, col="blue", lty="dashed" )
lines( xg, cdsFull@fitInfo[[cond]]$dispFunc( xg ) * qchisq( .95, df )/df, col="blue", lty="dashed" )
@ %$

For inference, we now specify two \emph{models} by formulas. The \emph{full model}
specifies that the genes' expression is influenced by both the library type and
the treatment condition, the \emph{reduced model} assumes that only the library
type has influence. For each gene, we fit generalized linear models (GLMs)
according to the two models, and then compare in orderto infer whether
the additional specification of the treatment improves the fit and hence, whether 
the treatment has significant effect.

<<fit1,cache=TRUE>>=
fit1 <- fitNbinomGLMs( cdsFull, count ~ type + condition )
fit0 <- fitNbinomGLMs( cdsFull, count ~ type  )
@
(These commands take a while to execute.)

For the actual test, we call
<<pvalsGLM,cache=TRUE>>=
pvalsGLM <- nbinomGLMTest( fit1, fit0 )
padjGLM <- p.adjust( pvalsGLM, method="BH" )
@

\begin{figure}
\centering
\includegraphics[width=.7\textwidth]{DESeq-figPval}
\caption{Comparison of p values (unadjusted) from the test using only the
four paired-end samples and
the test using all seven samples.}
\label{figPval}
\end{figure}

Let's compare with the result from the four-samples test:
<<addmarg2>>=
addmargins( table( `paired-end-only` = res$padj < .1, `all-samples` = padjGLM < .1 ) )
@

A more informative comparison might be a scatter plot of p values:
<<figPval,fig=TRUE>>=
plot( res$pval, pvalsGLM, log="xy", xlim=c(1e-17,1), ylim=c(1e-17,1), pch=20, cex=.3 )
@
The result is shown in Fig.~\ref{figPval}.

%-------------------------------------------------------------------------------------------------
\section{Moderated fold change estimates and applications to sample clustering and visualisation}
%-------------------------------------------------------------------------------------------------
In Section~\ref{sec:DE} we have seen how to use \Rpackage{DESeq} for
calling differentially expressed genes. For each gene,
\Rpackage{DESeq} reports a (log) fold--change estimate and a
$p$-value, as shown for instance in the dataframe \Robject{res} in the
beginning of that section.  When the involved counts are small, the
(log) fold--change estimate can be highly variable, and can even be
infinite.

For some purposes, such as the clustering of samples (or genes)
according to their overall profiles, or for visualisation of the data,
the (log) fold--changes may thus not be useful: the random variability
associated with fold--changes computed from ratios between low counts
might drown informative, systematic signal in other parts of the data.
We would like to \emph{moderate} the fold--change estimates in some
way, so that they are more amenable to plotting or clustering. One
approach to do so uses so-called pseudocounts: instead of the
log-ratio $\log_2(n_A/n_B)$ between the counts $n_A$, $n_B$ in two
conditions $A$ and $B$ consider $\log_2\left((n_A+c)/(n_B+c)\right)$,
where $c$ is a small positive number, e.\,g.\ $c=0.5$ or $c=1$.  For
small values of either $n_A$ or $n_B$, or both, the value of this term
is shifted towards 0 compared to the direct log-ratio
$\log_2(n_A/n_B)$. When $n_A$ and $n_B$ are both large, the direct
log-ratio and the log-ratio with pseudocounts (asymptotically) agree.
This approach is simple and intuitive, but it requires making a choice
for what value to use for $c$, and that may not be obvious.

A variant of this approach is to look for a mathematical function of
$n_A$ and $n_B$ that is like $\log_2(n_A/n_B)$ when $n_A$ and $n_B$
are large enough, but still behaves gracefully when they become
small. If we interpret \emph{graceful} as having the same variance
throughout, then we arrive at variance stabilising transformations
(VST)~\cite{Anders:2010:GB}. An advantage is that the parameters of
this function are chosen automatically based on the 
variability of the data, and no \emph{ad hoc} choice of $c$, as above,
is necessary. 
%
<<vsd>>=
cdsBlind <- estimateDispersions( cds, method="blind" )
vsd <- getVarianceStabilizedData( cdsBlind )
@


The data are now on a logarithm like scale, and we can compute
\emph{moderated log fold changes}.

<<modlr>>=
mod_lfc = (rowMeans( vsd[, conditions(cds)=="treated", drop=FALSE] ) - 
           rowMeans( vsd[, conditions(cds)=="untreated", drop=FALSE] ))
@ 

Now let us compare these to the original (log) fold changes. First we find that many of the latter
are infinite (resulting from division of a finite value by 0) or \emph{not a number} (NaN,
resulting from division of 0 by 0).
% FIXME: Simon, please check this - if you could please define 0/0 := 1 in the 
% appropriate place in the code, then the NaN can go away.

<<dah>>=
lfc = res$log2FoldChange
finite = is.finite(lfc)
table(as.character(lfc[!finite]), useNA="always")
@ 

For plotting (Figure~\ref{figmodlr}), we replace the infinite values by an arbitrary fixed large number:
<<repl>>=
LargeNumber = 10
lfc = ifelse(finite, lfc, sign(lfc)*LargeNumber)
@ 

<<figscp1, eval=FALSE>>=
plot( lfc, mod_lfc, pch=16, 
      col = ifelse(finite, "#80808040", "red"))
abline(a=0, b=1, col="#40404040")
@ 
<<figscp2, eval=TRUE, echo=FALSE, results=hide>>=
png(file="DESeq-figmodlr.png", width=800, height=800, pointsize=24)
plot( lfc, mod_lfc, pch=16, 
      col = ifelse(finite, "#80808040", "red"))
abline(a=0, b=1, col="#40404040")
dev.off()
@ 
% FIXME: why does  abs(lfc)>abs(mod_lfc)   not hold ??

\begin{figure}
\centering
\includegraphics[width=.7\textwidth]{DESeq-figmodlr.png}
\caption{Scatterplot of direct (\Robject{lfc}) versus \emph{moderated} log-ratios (\Robject{moderated\_lfc}).
  The moderation criterion used is variance stabilisation.
  The red points correspond to values that were infinite in \Robject{lfc}
  and were abitrarily set to \Sexpr{LargeNumber} for the purpose of plotting.
  These values vary in a finite range (as shown in the plot) in \Robject{moderated\_lfc}.}
\label{figmodlr}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=.49\textwidth]{DESeq-figHeatmap1}
\caption{Heatmap showing the Euclidean distances between the samples
  as calculated from the variance-stabilising transformation of the
  count data.}
\label{figHeatmap1}
\end{figure}

These data are now approximately homoscedastic and hence suitable as input to 
a sample to sample distance calculation,
%
<<dists>>=
dists <- dist( t( vsd ) )
@
%
which we can visualize as a heatmap in Figure~\ref{figHeatmap1}.
<<figHeatmap1,fig=TRUE>>=
heatmap(as.matrix( dists ), 
        symm=TRUE,
        scale="none",
        col = colorRampPalette(c("darkblue","white"))(100))
@

We can also visualise the expression data of, say, the top 100 differentially expressed genes.
%
<<figHeatmap2a,fig=TRUE>>=
select = order(res$pval)[1:100]
colors = colorRampPalette(c("white","darkblue"))(100)
heatmap( vsd[select,], 
         col = colors, scale = "none")
@
%
For comparison, let us also try the same with the untransformed counts.
%
<<figHeatmap2b,fig=TRUE>>=
heatmap( counts(cds)[select,], 
         col = colors, scale = "none")
@
The result is shown in Figure~\ref{figHeatmap2}.

\begin{figure}
\centering
\includegraphics[width=.49\textwidth]{DESeq-figHeatmap2a}
\includegraphics[width=.49\textwidth]{DESeq-figHeatmap2b}
\caption{Heatmaps showing the expression data of the top \Sexpr{length(select)}
  differentially expressed genes. Left: on a colour scale proportional 
  to the variance stabilisation transformed scale (\Robject{vsd}),
  right: colour scale proportional to the original count scale (\Robject{counts{cds}}).
  The right plot is dominated by a small number of data points with large values.}
\label{figHeatmap2}
\end{figure}


We note that the \Rfunction{heatmap} function that we have used here is rather basic, and that better
options exist, for instance the \Rfunction{heatmap.2} function from the package \Rpackage{gplots}
or the manual page for \Rfunction{dendrogramGrob} in the package \Rpackage{latticeExtra}.




\appendix

\section{Reference overview}

\textsl{TODO: Update or remove this!}

This appendix gives a terse overview of the class and all the functions defined in the package. The
description assumed that the reader is familiar with the \texttt{eSet} class.

The package defines one S4 class, \Rclass{CountDataSet}, which is derived from \Rclass{eSet}. To instantiate 
an object, use the function \Rfunction{newCountDataSet}. Do not call \Rfunction{new} directly.

The class's \texttt{assayData} is a locked environment containing a single object, namely the matrix
\texttt{counts} with the count data. The \texttt{featureData} is not used internally, but the user may
wish to store annotation there. The \texttt{phenoData} contains two columns, \texttt{\_sizeFactors}
and \texttt{\_conditions} to hold the vector of size factors and the factor of conditions. The user may add
further columns for annotation. 

Furthermore, there is a slot \texttt{rawVarFuncs} of type environment that holds the raw variance functions.
Each of these functions has a name to access it in the environment, which is either the name of a condition, or
\texttt{"\_max"} for conditions without replicates in normal mode, or \texttt{"\_blind"} or \texttt{"\_pooled"} for the single estimate that \Rfunction{estimateVarianceFunction} produces when called with \texttt{method="blind"}
or or \texttt{method="pooled"}.
Finally, the slot \texttt{rawVarFuncTable} contains a charcter vector which serves as a look-up table. 
The names are the conditions and the values are the function names, i.e., the hash keys for the \texttt{rawVarFuncs} environment.

All these properties are checked by the validity method.

The following slot accessors are provided: \Rfunction{counts}, \Rfunction{sizeFactors}, \Rfunction{conditions},
\Rfunction{rawVarFunc}, \Rfunction{rawVarFuncTable}. To avoid accidental invalidation, a setter is provided only for
\Rfunction{sizeFactors}. (The other slots may be change via the ``\texttt{@}'' syntax, but only at the user's risk.)

All functions that perform actual calculations are offered in two variants: a ``core'' one that takes base types as explicit
arguments, and a wrapper that takes a \Rclass{CountDataObject} and finds the data there itself. As these function pairs
have rather different argument lists, they are not made as generic functions, but rather have two different names, as follows:
\medskip

\small{\noindent
\begin{tabular}{lll}
Purpose & Wrapper function & Core function \\
\hline \\
estimate size factors & \texttt{estimateSizeFactors} & \texttt{estimateSizeFactorsForMatrix} \\
estimate variance functions & \Rfunction{estimateVarianceFunctions} & \Rfunction{estimateVarianceFunctionForMatrix} \\
calculate base means and variances & N/A & \Rfunction{getBaseMeansAndVariances} \\
get diagnostics for variance fit & \Rfunction{varianceFitDiagnostics} & \Rfunction{varianceFitDiagnosticsForMatrix} \\
produce ECDF plot for variance residuals & \Rfunction{residualsEcdfPlot} & \Rfunction{residualsEcdfPlotFromDiagnostics} \\
perform test & \Rfunction{nbinomTest} & \Rfunction{nbinomTestForMatrices} 
\end{tabular}
}

\section{Session Info}
<<sessi>>=
sessionInfo()
@

\bibliographystyle{unsrt} 
\bibliography{DESeq}


\end{document}
